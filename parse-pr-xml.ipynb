{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Test the xml parser on the Phys Rev archive data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is a test of the basic functions used for parsing the Physical Review xml file. The xml is approximately 40 MB and contains the information which you see in the pandas dataframe below. In what follows, I read the xml file and explore the created dataframe. Most of the information is parsed correctly. There are between 100 and 150 articles for which the author/affiliation information is corrupt and remains blank. That's pretty good preformance out of a total of 47000 articles. There is no pacs information for any of the articles here (the pacs classification sscheme was introduced in 1975). \n",
      "\n",
      "In earlier parsing functions, I was using pattern.web from the pattern module (http://www.clips.ua.ac.be/pattern) to read the information out of the xml file. I found out that creating the DOM for the xml was consuming a horrendous amount of memory (4 GB of RAM to parse a 40 MB xml file), and was pretty slow (5 min to parse the xml on my machine). Moreover, the built-in xml parser of the pattern module could not handle badly formed xml, for example incomplete cells. So, I decided to build a specialized parser for the particular xml documents at hand. This gave me a huge imporvement in memory use and speed. It now takes only 100 MB of RAM and 3 seconds to parse the xml file. Of course, there is no free lunch. The tools below are not a general purpose parser. \n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import re\n",
      "import string\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import apsparse"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# set custom css formatting for readability of the IPython notebook. See cs109.org\n",
      "from IPython.core.display import HTML\n",
      "styles = open('custom.css', 'r').read()\n",
      "HTML(styles)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<style>\n",
        "    @font-face {\n",
        "        font-family: \"Computer Modern\";\n",
        "        src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');\n",
        "    }\n",
        "    div.cell{\n",
        "        width:800px;\n",
        "        margin-left:16% !important;\n",
        "        margin-right:auto;\n",
        "    }\n",
        "    h1 {\n",
        "        font-family: Helvetica, serif;\n",
        "    }\n",
        "    h4{\n",
        "        margin-top:12px;\n",
        "        margin-bottom: 3px;\n",
        "       }\n",
        "    div.text_cell_render{\n",
        "        font-family: Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
        "        line-height: 145%;\n",
        "        font-size: 130%;\n",
        "        width:800px;\n",
        "        margin-left:auto;\n",
        "        margin-right:auto;\n",
        "    }\n",
        "\n",
        "    div.text_cell_render li {\n",
        "        line-height: 145%;\n",
        "    }\n",
        "\n",
        "    div.text_cell_render code {\n",
        "        color: rgb(40, 114, 43);\n",
        "        font-family: \"Source Code Pro\", source-code-pro,Consolas, monospace;\n",
        "        font-size: 80%;\n",
        "    }\n",
        "\n",
        "    .CodeMirror{\n",
        "            font-family: \"Source Code Pro\", source-code-pro,Consolas, monospace;\n",
        "    }\n",
        "\n",
        "    .text_cell_render h5 {\n",
        "        font-weight: 300;\n",
        "        font-size: 16pt;\n",
        "        color: #4057A1;\n",
        "        font-style: italic;\n",
        "        margin-bottom: .5em;\n",
        "        margin-top: 0.5em;\n",
        "        display: block;\n",
        "    }\n",
        "\n",
        "    .warning{\n",
        "        color: rgb( 240, 20, 20 )\n",
        "        }\n",
        "\n",
        "    strong{\n",
        "        color: rgb(23, 103, 140);\n",
        "\tborder: 1px solid;\n",
        "    }\n",
        "\n",
        "</style>\n",
        "<script>\n",
        "    MathJax.Hub.Config({\n",
        "                        TeX: {\n",
        "                           extensions: [\"AMSmath.js\"]\n",
        "                           },\n",
        "                tex2jax: {\n",
        "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
        "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
        "                },\n",
        "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
        "                \"HTML-CSS\": {\n",
        "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
        "                }\n",
        "        });\n",
        "</script>\n"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "<IPython.core.display.HTML at 0x7f4b324456d0>"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Read an xml formatted file to string"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "datapath = os.path.join('aps-data','aps-dataset-metadata-2010','PR.xml')\n",
      "f = open(datapath,'r')\n",
      "PR_file = f.read()\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "entry_df = apsparse.xml_string_to_dataframe(PR_file)\n",
      "print entry_df.shape\n",
      "entry_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of dropped_entries: 0\n",
        "(47941, 8)\n"
       ]
      },
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>authors</th>\n",
        "      <th>doi</th>\n",
        "      <th>journ_sec</th>\n",
        "      <th>journal</th>\n",
        "      <th>pacs</th>\n",
        "      <th>print_date</th>\n",
        "      <th>publication_year</th>\n",
        "      <th>title</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> [(David W Cornelius, Laboratory of Physics, Un...</td>\n",
        "      <td> 10.1103/PhysRev.1.16</td>\n",
        "      <td> Articles</td>\n",
        "      <td> Physical Review</td>\n",
        "      <td> []</td>\n",
        "      <td> 1913-01-00</td>\n",
        "      <td> 1913</td>\n",
        "      <td> The Velocity of Electrons in the Photo-electri...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>                                                []</td>\n",
        "      <td>  10.1103/PhysRev.1.1</td>\n",
        "      <td> Articles</td>\n",
        "      <td> Physical Review</td>\n",
        "      <td> []</td>\n",
        "      <td> 1913-01-00</td>\n",
        "      <td> 1913</td>\n",
        "      <td> Announcement of the Transfer of the Review to ...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>               [(A D Cole, Ohio State University)]</td>\n",
        "      <td>  10.1103/PhysRev.1.2</td>\n",
        "      <td> Articles</td>\n",
        "      <td> Physical Review</td>\n",
        "      <td> []</td>\n",
        "      <td> 1913-01-00</td>\n",
        "      <td> 1913</td>\n",
        "      <td> Diffraction and Secondary Radiation with Elect...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> [(S J Allen, University of Cincinnati), (E J L...</td>\n",
        "      <td> 10.1103/PhysRev.1.35</td>\n",
        "      <td> Articles</td>\n",
        "      <td> Physical Review</td>\n",
        "      <td> []</td>\n",
        "      <td> 1913-01-00</td>\n",
        "      <td> 1913</td>\n",
        "      <td>     On the Comparative Absorption of \u03b3 and X Rays</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> [(A L Clark, Queen's University, Kingston, Ont...</td>\n",
        "      <td> 10.1103/PhysRev.1.50</td>\n",
        "      <td> Articles</td>\n",
        "      <td> Physical Review</td>\n",
        "      <td> []</td>\n",
        "      <td> 1913-01-00</td>\n",
        "      <td> 1913</td>\n",
        "      <td>            Study of Resistance of Carbon Contacts</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 8 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "                                             authors                   doi  \\\n",
        "0  [(David W Cornelius, Laboratory of Physics, Un...  10.1103/PhysRev.1.16   \n",
        "1                                                 []   10.1103/PhysRev.1.1   \n",
        "2                [(A D Cole, Ohio State University)]   10.1103/PhysRev.1.2   \n",
        "3  [(S J Allen, University of Cincinnati), (E J L...  10.1103/PhysRev.1.35   \n",
        "4  [(A L Clark, Queen's University, Kingston, Ont...  10.1103/PhysRev.1.50   \n",
        "\n",
        "  journ_sec          journal pacs  print_date publication_year  \\\n",
        "0  Articles  Physical Review   []  1913-01-00             1913   \n",
        "1  Articles  Physical Review   []  1913-01-00             1913   \n",
        "2  Articles  Physical Review   []  1913-01-00             1913   \n",
        "3  Articles  Physical Review   []  1913-01-00             1913   \n",
        "4  Articles  Physical Review   []  1913-01-00             1913   \n",
        "\n",
        "                                               title  \n",
        "0  The Velocity of Electrons in the Photo-electri...  \n",
        "1  Announcement of the Transfer of the Review to ...  \n",
        "2  Diffraction and Secondary Radiation with Elect...  \n",
        "3      On the Comparative Absorption of \u03b3 and X Rays  \n",
        "4             Study of Resistance of Carbon Contacts  \n",
        "\n",
        "[5 rows x 8 columns]"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Find what kinds of articles are included, and break the dataframe into different categories"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "article_types = entry_df.journ_sec.unique().tolist()\n",
      "print article_types"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['Articles', 'American Physical Society', 'Proceedings of the American Physical Society', 'New Books', 'Errata', 'Letters to the Editor', 'Erratum', 'Important Announcement', 'Proceeding of the American Physical Society', 'Announcement', 'Editorial', 'ANNOUNCEMENT', 'EDITORIAL', 'Comments', 'Comments and Addenda', 'Comments and Addendum', 'Corrections', 'Book Notices', 'Proceedings of the American Physical Society.', 'Book Reviews and Notices', 'Book Reviews', 'Rapid Communications', 'Proceedings of The American Physical Society', 'PROCEEDINGS OF THE AMERICAN PHYSICAL SOCIETY', 'ERRATA', 'Proceedings of the American Physical Society, Reno, Nevada June 23, 1927, Vol. 30, p. 362, September, 1927', 'Proceeding of The American Physical Society', 'Ferromagnetic Symposium and Conference at the Summer Meeting of the American Physical Society at Schenectady, September 12, 1931', 'Errata and Addenda', 'Letter to the Editor', 'Proceedings of the Metropolitan Section of the American Physical Society, October 29, 1937', '', 'Program of Research Papers at the Annual Meeting of the Southeastern Section of the American Physical Society University of Alabama, Tuscaloosa, Alabama April 1 and 2, 1938', 'Organization Meeting of the New York State Section of the American Physical Society Union College, Schenectady April 2, 1938', 'Proceedings of the New England Section of the American Physical Society', 'Proceedings of the Metropolitan Section of the American Physical Society, March 25, 1938', 'Proceedings of the Metropolitan Section of the American Physical Society', 'Proceedings of the New York State Section of the American Physical Society', 'Proceedings of the Ohio Section of the American Physical Society', 'Dallas Meeting of Section B, A.A.A.S., and the American Association of Physics Teachers', 'Proceedings of the Southeastern Section of the American Physical Society', 'Proceedings of the Southestern Section of the American Physical Society', 'Report of the 1946 Spring Meeting of the American Society for X-Ray and Election Diffraction', 'Proceedings to the American Physical Society', 'Proceedings of the American Physical Socity', 'John Torrence Tate', 'Proceedings of the American Physical']\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "article_category = ['Articles','Letters to the Editor','Letter to the Editor','Rapid Communications']\n",
      "comment_category = ['Errata', 'Erratum', 'Comments', 'Comments and Addenda', \n",
      "                    'Comments and Addendum', 'Corrections', 'ERRATA',  'Errata and Addenda']\n",
      "proceeding_category = ['American Physical Society', 'Proceedings of the American Physical Society','Proceedings of the American Physical Society.',\n",
      "                        'Proceedings of The American Physical Society', 'PROCEEDINGS OF THE AMERICAN PHYSICAL SOCIETY', \n",
      "                        'Proceedings of the American Physical Society, Reno, Nevada June 23, 1927, Vol. 30, p. 362, September, 1927', \n",
      "                        'Proceeding of The American Physical Society', \n",
      "                        'Ferromagnetic Symposium and Conference at the Summer Meeting of the American Physical Society at Schenectady, September 12, 1931', \n",
      "                        'Proceedings of the Metropolitan Section of the American Physical Society, October 29, 1937',\n",
      "                        'Program of Research Papers at the Annual Meeting of the Southeastern Section of the American Physical Society University of Alabama, Tuscaloosa, Alabama April 1 and 2, 1938', \n",
      "                        'Organization Meeting of the New York State Section of the American Physical Society Union College, Schenectady April 2, 1938', \n",
      "                        'Proceedings of the New England Section of the American Physical Society', \n",
      "                        'Proceedings of the Metropolitan Section of the American Physical Society, March 25, 1938', \n",
      "                        'Proceedings of the Metropolitan Section of the American Physical Society', \n",
      "                        'Proceedings of the New York State Section of the American Physical Society', \n",
      "                        'Proceedings of the Ohio Section of the American Physical Society', \n",
      "                        'Dallas Meeting of Section B, A.A.A.S., and the American Association of Physics Teachers', \n",
      "                        'Proceedings of the Southeastern Section of the American Physical Society', \n",
      "                        'Proceedings of the Southestern Section of the American Physical Society', \n",
      "                        'Report of the 1946 Spring Meeting of the American Society for X-Ray and Election Diffraction', \n",
      "                        'Proceedings to the American Physical Society', \n",
      "                        'Proceedings of the American Physical Socity', \n",
      "                        'Proceedings of the American Physical']\n",
      "blank_category = ['','John Torrence Tate']\n",
      "editor_category= ['New Books', 'Important Announcement', 'Announcement', 'Editorial', 'ANNOUNCEMENT', 'EDITORIAL',\n",
      "                  'Book Notices', 'Book Reviews and Notices', 'Book Reviews'] "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "articles = entry_df[entry_df.journ_sec.map(lambda x: x in article_category)]\n",
      "comments = entry_df[entry_df.journ_sec.map(lambda x: x in comment_category)]\n",
      "proceedings = entry_df[entry_df.journ_sec.map(lambda x: x in proceeding_category)]\n",
      "editorials = entry_df[entry_df.journ_sec.map(lambda x: x in editor_category)]\n",
      "uncategorized = entry_df[entry_df.journ_sec.map(lambda x: x in blank_category)]\n",
      "print 'Total entries: %d' % entry_df.shape[0]\n",
      "print 'Article entries: %d' % articles.shape[0]\n",
      "print 'Comment entries: %d' % comments.shape[0]\n",
      "print 'Proceeding entries: %d' % proceedings.shape[0]\n",
      "print 'Editorial entries: %d' % editorials.shape[0]\n",
      "print 'Uncategorized entries: %d' % uncategorized.shape[0]\n",
      "uncategorized.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Total entries: 47941\n",
        "Article entries: 46096\n",
        "Comment entries: 1022\n",
        "Proceeding entries: 635\n",
        "Editorial entries: 183\n",
        "Uncategorized entries: 2\n"
       ]
      },
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>authors</th>\n",
        "      <th>doi</th>\n",
        "      <th>journ_sec</th>\n",
        "      <th>journal</th>\n",
        "      <th>pacs</th>\n",
        "      <th>print_date</th>\n",
        "      <th>publication_year</th>\n",
        "      <th>title</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>33353</th>\n",
        "      <td> []</td>\n",
        "      <td> 10.1103/PhysRev.53.107.2</td>\n",
        "      <td>                   </td>\n",
        "      <td> Physical Review</td>\n",
        "      <td> []</td>\n",
        "      <td> 1938-01-01</td>\n",
        "      <td> 1938</td>\n",
        "      <td> Minutes of the Wellesley Meeting October 23, 1937</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>39991</th>\n",
        "      <td> []</td>\n",
        "      <td>     10.1103/PhysRev.79.1</td>\n",
        "      <td> John Torrence Tate</td>\n",
        "      <td> Physical Review</td>\n",
        "      <td> []</td>\n",
        "      <td> 1950-07-01</td>\n",
        "      <td> 1950</td>\n",
        "      <td>                                John Torrence Tate</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>2 rows \u00d7 8 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "      authors                       doi           journ_sec          journal  \\\n",
        "33353      []  10.1103/PhysRev.53.107.2                      Physical Review   \n",
        "39991      []      10.1103/PhysRev.79.1  John Torrence Tate  Physical Review   \n",
        "\n",
        "      pacs  print_date publication_year  \\\n",
        "33353   []  1938-01-01             1938   \n",
        "39991   []  1950-07-01             1950   \n",
        "\n",
        "                                                   title  \n",
        "33353  Minutes of the Wellesley Meeting October 23, 1937  \n",
        "39991                                 John Torrence Tate  \n",
        "\n",
        "[2 rows x 8 columns]"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Fix uncategorized entries -> done except for 2 comments and articles"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#entries_list = PRL_file.split('</article>')\n",
      "#entries_list = entries_list[:-1]\n",
      "#print entries_list[30193]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Test for problems in journal, print_date, journ_sec, doi, title, authors, and copyright  identification"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def authors_ok(auth):\n",
      "    try:\n",
      "        ok = len(auth)>0\n",
      "        for a  in auth:\n",
      "            ok = ok and (not a[0] is None)\n",
      "    except:\n",
      "        return False\n",
      "    return ok\n",
      " \n",
      "#x = articles.authors[0]\n",
      "#authors_ok(x)\n",
      "df2 = articles[articles.authors.map(lambda x: authors_ok(x) )]\n",
      "print 'Found %d articles with properly parsed author name information.' % df2.shape[0] # ok\n",
      "#df2.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Found 46071 articles with properly parsed author name information.\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def affiliations_ok(auth):\n",
      "    try:\n",
      "        ok = len(auth)>0\n",
      "        for a  in auth:\n",
      "            ok = ok and (not a[1] is None)\n",
      "    except:\n",
      "        return False\n",
      "    return ok\n",
      " \n",
      "#x = articles.authors[0]\n",
      "#authors_ok(x)\n",
      "df2 = articles[articles.authors.map(lambda x: affiliations_ok(x) )]\n",
      "print 'Found %d articles with propperly parsed author affiliation information' % df2.shape[0] # ok\n",
      "#df2.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Found 45933 articles with propperly parsed author affiliation information\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df2 = articles[articles['pacs'].map(lambda x: len(x)==0)]\n",
      "print 'Found %d articles without pacs number information.' % df2.shape[0]#ok\n",
      "year_list = df2.publication_year.tolist()\n",
      "year_list = [int(x) for x in year_list]\n",
      "print 'Missing pacs are between years %d and %d.' %(min(year_list),max(year_list))\n",
      "all_year_list = articles.publication_year.tolist()\n",
      "all_year_list = [int(x) for x in all_year_list]\n",
      "num_no_pacs = len([x for x in all_year_list if x<1975])\n",
      "print 'Pacs was introduced in 1975. Number of articles before 1975: %d' % num_no_pacs\n",
      "print 'This leaves %d articles published in 1975 and later with improperly parsed pacs information.' % (df2.shape[0]-num_no_pacs)\n",
      "#df2.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Found 46096 articles without pacs number information.\n",
        "Missing pacs are between years 1913 and 1969.\n",
        "Pacs was introduced in 1975. Number of articles before 1975: 46096\n",
        "This leaves 0 articles published in 1975 and later with improperly parsed pacs information.\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df2 = entry_df[entry_df['print_date'].map(lambda x: len(x)==10)]\n",
      "print '%d out of %d publication dates were correctly parsed.' % (df2.shape[0],entry_df.shape[0])#ok"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "47941 out of 47941 publication dates were correctly parsed.\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df2 = entry_df[entry_df['publication_year'].map(lambda x: 1890<=int(x)<=1970)]\n",
      "print '%d out of %d publication years were correctly parsed.' % (df2.shape[0],entry_df.shape[0])#okdf2.shape # ok"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "47941 out of 47941 publication years were correctly parsed.\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def doi_ok(doi_str,core_str):\n",
      "    '''\n",
      "    check if aa doi string has the expected formatting\n",
      "    '''\n",
      "    p = re.compile(core_str+'.[0-9]{1,3}.[0-9]{1,6}')\n",
      "    # 10.1103/PhysRevLett.85.5559\n",
      "    m = p.search(doi_str)\n",
      "    if m:\n",
      "        return True\n",
      "    else:\n",
      "        return False\n",
      "#print doi_ok('10.1103/PhysRevLett.85.5559','10.1103/PhysRevLett')\n",
      "\n",
      "df2 = entry_df[entry_df['doi'].map(lambda x: doi_ok(x,'10.1103/PhysRev'))]\n",
      "print '%d out of %d doi numbers were correctly parsed.' % (df2.shape[0],entry_df.shape[0])#ok"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "47941 out of 47941 doi numbers were correctly parsed.\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Appendix: Test and development using function snippets (can be confusing)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Test parsing of the author group string"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "try:\n",
      "    affiliation = authgrp.split('</aff>')[0].split('<aff>')[1]\n",
      "except:\n",
      "    affiliation = None\n",
      "print affiliation\n",
      "authors = []\n",
      "cnt = 0\n",
      "auth_lst = authgrp.split('<aff>')[0]\n",
      "##\n",
      "author, auth_lst = get_content_rest(auth_lst,'author')\n",
      "first,restname = get_content_rest(author,'givenname')\n",
      "mid, restname = get_content_rest(restname,'middlename')\n",
      "last,restname = get_content_rest(restname,'surname')\n",
      "authors.append((string.join([first,mid,last]).replace('.',''),affiliation))\n",
      "print authors[0]\n",
      "print auth_lst\n",
      "author, auth_lst = get_content_rest(auth_lst,'author')\n",
      "first,restname = get_content_rest(author,'givenname')\n",
      "mid, restname = get_content_rest(restname,'middlename')\n",
      "last,restname = get_content_rest(restname,'surname')\n",
      "authors.append((string.join([first,mid,last]).replace('.',''),affiliation))\n",
      "print authors[1]\n",
      "print len(auth_lst)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Laboratory of Physics, University of Illinois\n",
        "('David W Cornelius', 'Laboratory of Physics, University of Illinois')\n",
        "\n",
        "</author>\n",
        "('  ', 'Laboratory of Physics, University of Illinois')\n",
        "10\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Test parsing of each article string"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "entry = entries_list[0]\n",
      "subsplit = entry.split('</journal>')\n",
      "journal  = subsplit[0]\n",
      "journal = journal[journal.rfind('>')+1:]\n",
      "subsplit = subsplit[1].split('</tocsec>')\n",
      "journ_sec = subsplit[0].split('<tocsec>')[1]\n",
      "subsplit = subsplit[1].split('</doi>')\n",
      "doi = subsplit[0].split('<doi>')[1]\n",
      "subsplit = subsplit[1].split('</title>')\n",
      "title = subsplit[0].split('<title>')[1]\n",
      "subsplit = subsplit[1].split('</authgrp>')\n",
      "# here add the function which returns the list of (author,affiliation) tuples\n",
      "print journal"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Physical Review\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Test parsing of xml content"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "string_in = '<aa>date = \"0000-00-00\" <></aa>\\n<b>B</b>\\n<b>BB</b>\\n<c>C</c>'\n",
      "tag_str = '<b>'\n",
      "tag_str_exception = 'd'\n",
      "start_plus = 0\n",
      "end_minus = 0\n",
      "c,r = get_content_rest(string_in,'<aa>','</aa>','[0-9]{4,4}-[0-9]{2,2}-[0-9]{2,2}')\n",
      "print c,r"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0000-00-00 \n",
        "<b>B</b>\n",
        "<b>BB</b>\n",
        "<c>C</c>\n"
       ]
      }
     ],
     "prompt_number": 189
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Test regular expression matching"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#s = '<author anref=\"n2\"><givenname>W.</givenname><middlename>H.</middlename><surname>Tanttila</surname></author><aff>University of Washington, Seattle, Washington</aff></authgrp>'\n",
      "#print s\n",
      "#p = re.compile(' anref=\"[a-zA-Z0-9]*\"')\n",
      "#m = p.search(s)\n",
      "#print string.replace(s,m.group(),'')\n",
      "s = '<journal jcode=\"PR\" short=\"Phys. Rev.\">Physical Review</journal>'\n",
      "print regularize_entry(s)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<journal>Physical Review</journal>\n"
       ]
      }
     ],
     "prompt_number": 88
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Test author list parsing"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "authgrp_str = string.join(['<authgrp>\\n<author><givenname>F.</givenname><middlename>B.</middlename>',\n",
      "'<surname>Harris</surname></author>\\n<aff>Massachusetts Institute of Technology, Laboratory ',\n",
      "'for Nuclear Science, Cambridge, Massachusetts</aff>\\n</authgrp>\\n',\n",
      "'<authgrp>\\n<author><givenname>I.</givenname><middlename>Escobar</middlename>',\n",
      "'<surname>V.</surname></author>\\n<aff>Universidad Mayor de San Andr\u00e9s, La Paz, Bolivia</aff>',\n",
      "'\\n</authgrp>'])\n",
      "#print authgrp_str\n",
      "al = make_author_list(authgrp_str)\n",
      "print al"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<givenname>F.</givenname><middlename>B.</middlename> <surname>Harris</surname>\n",
        "F.\n",
        "[('F B Harris', 'Massachusetts Institute of Technology, Laboratory  for Nuclear Science, Cambridge, Massachusetts')]\n"
       ]
      }
     ],
     "prompt_number": 129
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Test parsing of PRL "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#entries_list = PRL_file.split('</article>')\n",
      "#PR_file = PRL_file[:1347]\n",
      "#print PR_file\n",
      "#entry  = PR_file\n",
      "entry = entries_list[67000]\n",
      "entry = regularize_entry(entry)\n",
      "print entry\n",
      "journal, subsplit = get_content_rest(entry, 'journal')\n",
      "print journal\n",
      "print_date, subsplit = get_content_rest(subsplit, '<issue','</issue>','[0-9]{4,4}-[0-9]{2,2}-[0-9]{2,2}')\n",
      "print print_date\n",
      "journ_sec, subsplit = get_content_rest(subsplit,'<tocsec','tocsec>','>[a-zA-Z ,.:\"]*<')\n",
      "journ_sec = string.replace(journ_sec,'<','')\n",
      "journ_sec = string.replace(journ_sec,'>','')\n",
      "print journ_sec\n",
      "doi, subsplit = get_content_rest(subsplit,'doi')\n",
      "print doi\n",
      "title, subsplit = get_content_rest(subsplit,'title')\n",
      "print title\n",
      "authors = []\n",
      "while string.find(subsplit,'<authgrp>')>-1:\n",
      "    authgrp, subsplit = get_content_rest(subsplit,'authgrp')\n",
      "    #print subsplit\n",
      "    #resp = raw_input('Continue? (y/n) ')\n",
      "    #cont = resp == 'y'\n",
      "    #print authgrp\n",
      "    al = make_author_list(authgrp)\n",
      "    #print al\n",
      "    authors.extend(al)\n",
      "print authors\n",
      "copyrtdate, subsplit = get_content_rest(subsplit,'<cpyrtdate', '</cpyrtholder>','[0-9]{4,4}')\n",
      "print copyrtdate"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<article doi=\"10.1103/PhysRevLett.89.018301\">\n",
        "<journal>Physical Review Letters</journal>\n",
        "<volume>89</volume>\n",
        "<issue printdate=\"2002-07-01\">1</issue>\n",
        "<eid>018301</eid>\n",
        "<numpages>4</numpages>\n",
        "<price></price><tocsec code=\"L8-83A\">Interdisciplinary Physics: Biological Physics, Quantum Information, etc.</tocsec>\n",
        "<arttype type=\"article\"></arttype><doi>10.1103/PhysRevLett.89.018301</doi>\n",
        "<title>Quantum-Classical Transition Induced by Electrical Measurement</title>\n",
        "<authgrp>\n",
        "<author><givenname>D.</givenname><surname>Mozyrsky</surname></author>\n",
        "<author><givenname>I.</givenname><surname>Martin</surname></author>\n",
        "<aff>Theoretical Division, Los Alamos National Laboratory, Los Alamos, New Mexico 87545</aff>\n",
        "</authgrp>\n",
        "<history>\n",
        "<received date=\"2002-03-25\"/>\n",
        "<published date=\"2002-06-13\"/>\n",
        "</history>\n",
        "<pacs>\n",
        "<pacscode>85.85.+j</pacscode>\n",
        "<pacscode>05.30.-d</pacscode>\n",
        "<pacscode>05.60.Gg</pacscode>\n",
        "</pacs>\n",
        "<cpyrt>\n",
        "<cpyrtdate date=\"2002\" /><cpyrtholder>The American Physical Society</cpyrtholder>\n",
        "</cpyrt>\n",
        "\n",
        "Physical Review Letters\n",
        "2002-07-01\n",
        "Interdisciplinary Physics: Biological Physics, Quantum Information, etc.\n",
        "10.1103/PhysRevLett.89.018301\n",
        "Quantum-Classical Transition Induced by Electrical Measurement\n",
        "[('D  Mozyrsky', 'Theoretical Division, Los Alamos National Laboratory, Los Alamos, New Mexico 87545'), ('I  Martin', 'Theoretical Division, Los Alamos National Laboratory, Los Alamos, New Mexico 87545')]\n",
        "2002\n"
       ]
      }
     ],
     "prompt_number": 86
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "entries_list = PRL_file.split('</article>')\n",
      "entry = entries_list[83215]\n",
      "#entry = regularize_entry(entry)\n",
      "#print 'entry:',entry\n",
      "#for ch in entry:\n",
      "#    print 'character:',ch\n",
      "journal, subsplit = get_content_rest(entry, '<journal','/journal>','>[a-zA-Z ]*<')\n",
      "#if len(journal)==0:\n",
      "#    print 'entry 1:',entry\n",
      "journal = string.replace(journal,'<','')\n",
      "journal = string.replace(journal,'>','')\n",
      "print journal\n",
      "print_date, subsplit = get_content_rest(subsplit, '<issue','/issue>','[0-9]{4,4}-[0-9]{2,2}-[0-9]{2,2}')\n",
      "try:\n",
      "    journ_sec, subsplit = get_content_rest(subsplit,'<tocsec','/tocsec>','>[a-zA-Z ,.:\"]*<') ## NOT HERE!!!!\n",
      "except:\n",
      "    journ_sec = ''\n",
      "journ_sec = string.replace(journ_sec,'<','')\n",
      "journ_sec = string.replace(journ_sec,'>','')\n",
      "print journ_sec\n",
      "doi, subsplit = get_content_rest(subsplit,'doi')\n",
      "title, subsplit = get_content_rest(subsplit,'title')\n",
      "print doi\n",
      "print title\n",
      "#print subsplit\n",
      "authors = []\n",
      "if terms_matched(subsplit,['authgrp']):\n",
      "    while string.find(subsplit,'<authgrp>')>-1:\n",
      "        authgrp, subsplit = get_content_rest(subsplit,'authgrp')\n",
      "        al = make_author_list(authgrp)\n",
      "        authors.extend(al)\n",
      "        print subsplit\n",
      "else:\n",
      "    count = 0\n",
      "    while string.find(subsplit,'author')>-1:\n",
      "        authgrp, subsplit = get_content_rest(subsplit,'<author','/author>','>[<>./a-zA-Z]*<')\n",
      "        al = make_author_list('<author'+authgrp+'/author>')\n",
      "        authors.extend(al)\n",
      "        count += 1\n",
      "        if count >10:\n",
      "            break      \n",
      "#try:\n",
      "#    copyrtdate, subsplit = get_content_rest(subsplit,'<cpyrtdate', '</cpyrtholder>','[0-9]{4,4}')\n",
      "#except:\n",
      "#    copyrtdate = print_date[:4]\n",
      "print authors\n",
      "print subsplit\n",
      "copyrtdate = print_date[:4]\n",
      "if len(copyrtdate)!=4:\n",
      "    print 'Warning: parsed incorrect  date  information for doi:',doi\n",
      "    print 'date:', copyrtdate"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Physical Review Letters\n",
        "Condensed Matter: Structure, etc.\n",
        "10.1103/PhysRevLett.97.175503\n",
        "Capillary Filling of Anodized Alumina Nanopore Arrays\n",
        "[('Kyle J Alvine', None), ('Oleg G Shpyrko', None), ('Peter S Pershan', None), ('Kyusoon  Shin', None), ('Thomas P Russell', None)]\n",
        "<aff affid=\"a1\">Division of Engineering and Applied Sciences, <institution>Harvard University</institution>, Cambridge, Massachusetts 02138, USA<published date=\"2006-10-27\"/></history><pacs pacsyr=\"2006\"><pacscode>61.10.Eq</pacscode><pacscode>05.70.\u2212a</pacscode><pacscode>68.08.Bc</pacscode></pacs><cpyrt><cpyrtdate date=\"2006\"/><cpyrtholder>The American Physical Society</cpyrtholder></cpyrt> \n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "These are the functions in apsparse.py. Check the py file for the most recent versions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def terms_matched(entry, terms_list_twice=[], terms_list_thrice = []):\n",
      "    '''\n",
      "    check that all strings in the list terms_list_twice appear in the string 'entry' exactly twice\n",
      "    and all strings in the list terms_list_thrice appear in the string 'entry' exactly three times\n",
      "    returns a boolean\n",
      "    '''\n",
      "    for term in terms_list_twice:\n",
      "        if string.count(entry,term) <> 2:\n",
      "            return False\n",
      "    for term in terms_list_thrice:\n",
      "        if string.count(entry,term) <> 3:\n",
      "            return False\n",
      "    return True\n",
      "\n",
      "def get_content_rest(string_in, tag_str, tag_str_exception = '', reg_expr = ''):\n",
      "    '''\n",
      "    Split an xml formatted string. Return a tuple of two strings, content and rest.\n",
      "    The asssumed format of string_in is:\n",
      "    <tag_str>content</tag_str>rest\n",
      "    except if non-empty tag_str_exception is provided, when I assume the format:\n",
      "    <tag_str>'ignored'reg_expr'ignored'<tag_str_excpetion>rest\n",
      "    In the latter case, a regular expression string describes the format of the content \n",
      "    which gets returned. In both cases, rest is the part of string_in after the end of \n",
      "    the </tag_str> or <tag_sre_exception> substring\n",
      "    '''\n",
      "    if len(tag_str_exception)==0:\n",
      "        l = '<'+tag_str+'>'\n",
      "        h = '</'+tag_str+'>'\n",
      "    else:\n",
      "        l = tag_str\n",
      "        h = tag_str_exception\n",
      "    if string.find(string_in,l)>-1:\n",
      "        Ilow =  string.find(string_in,l)+len(l)\n",
      "    else:\n",
      "        Ilow = 0\n",
      "    if string.find(string_in,h)>-1:\n",
      "        Ihigh = string.find(string_in,h)\n",
      "    else:\n",
      "        Ihigh, end_minus = 0,0\n",
      "        h = ''\n",
      "    if len(reg_expr) == 0:\n",
      "        content = string_in[Ilow:Ihigh]\n",
      "    else:\n",
      "        p = re.compile(reg_expr)\n",
      "        m = p.search(string_in[Ilow:Ihigh])\n",
      "        if m:\n",
      "            content = m.group()\n",
      "        else:\n",
      "            content = ''\n",
      "    rest = string_in[Ihigh+len(h):]\n",
      "    return content,rest\n",
      "\n",
      "def make_author_list(authgrp_str):\n",
      "    '''\n",
      "    Make a list of (author, affiliation) tuples for the author group in authgrp_str\n",
      "    If there is no affiliation in the group, affiliation is set to ''\n",
      "    Returns: authors, a list of (author,affiliation)\n",
      "    '''\n",
      "    try:\n",
      "        affiliation = authgrp_str.split('</aff>')[0].split('<aff>')[1]\n",
      "    except:\n",
      "        affiliation = None\n",
      "    cnt = 0\n",
      "    authors = []\n",
      "    auth_lst = authgrp_str.split('<aff>')[0]\n",
      "    while 1:\n",
      "        author, auth_lst = get_content_rest(auth_lst,'author')\n",
      "        first,restname = get_content_rest(author,'givenname')\n",
      "        mid, restname = get_content_rest(restname,'middlename')\n",
      "        last,restname = get_content_rest(restname,'surname')\n",
      "        authors.append((string.join([first,mid,last]).replace('.',''),affiliation))\n",
      "        if len(auth_lst)<11:\n",
      "            break\n",
      "        cnt += 1\n",
      "        if cnt>10:\n",
      "            break\n",
      "    return authors\n",
      "\n",
      "def make_pacs_list(string_in):\n",
      "    '''\n",
      "    Get the list of pacs numbers.\n",
      "    '''\n",
      "    pacs = []\n",
      "    sub = string_in\n",
      "    if string.find(sub,'<pacs')>-1 and string.find(sub,'</pacs')>-1:\n",
      "        count = 0\n",
      "        while string.find(sub,'<pacscode>')>-1:\n",
      "            newpacs, sub = get_content_rest(sub,'pacscode')\n",
      "            pacs.extend([newpacs])\n",
      "            count += 1\n",
      "            if count > 10:\n",
      "                break\n",
      "    else:\n",
      "        pacs = []\n",
      "    return pacs,sub\n",
      "\n",
      "def regularize_entry(strng):\n",
      "    '''\n",
      "    Fix known html formatting issues in the article entry xml strings\n",
      "    '''\n",
      "    strout = string.replace(strng,'\\n',' ')\n",
      "    strout = string.replace(strout,'aff >','aff>')\n",
      "    p = re.compile(' anref=\"[a-zA-Z0-9]*\"')\n",
      "    m = p.search(strout)\n",
      "    if m:\n",
      "        strout = string.replace(strout,m.group(),'')\n",
      "    p = re.compile(' jcode=\"[a-zA-Z.= \"]*\"')\n",
      "    m = p.search(strout)\n",
      "    if m:\n",
      "        strout = string.replace(strout,m.group(),'')\n",
      "    return strout\n",
      "\n",
      "def get_authors(string_in):\n",
      "    '''\n",
      "    get the list of authors and affiliations. handles the bad xml formatting cases\n",
      "    '''\n",
      "    authors = []\n",
      "    sub = string_in\n",
      "    if string.find(sub,'</authgrp')>-1:\n",
      "        count = 0\n",
      "        while string.find(sub,'<authgrp>')>-1:\n",
      "            authgrp, sub = get_content_rest(sub,'authgrp')\n",
      "            al = make_author_list(authgrp)\n",
      "            authors.extend(al)\n",
      "            count += 1\n",
      "            if count > 100:\n",
      "                break\n",
      "    else:\n",
      "        count = 0\n",
      "        while string.find(sub,'author')>-1:\n",
      "            authgrp, sub = get_content_rest(sub,'<author','/author>','>[<>./a-zA-Z]*<')\n",
      "            al = make_author_list('<author'+authgrp+'/author>')\n",
      "            authors.extend(al)\n",
      "            count += 1\n",
      "            if count > 101:\n",
      "                break\n",
      "    return authors,sub\n",
      "\n",
      "def xml_string_to_dataframe(strin):\n",
      "    '''\n",
      "    Parse an xml string and put the information in a pandas DataFrame. \n",
      "    The xml string consists of repeated blocks of the following form:\n",
      "    <article doi=\"00.0000/ABCD.0.0\">\n",
      "    <journal jcode=\"AB\" short=\"ABCDEF\">ABCDEFGH</journal>\n",
      "    <volume>0</volume>\n",
      "    <issue printdate=\"0000-00-00\">0</issue>\n",
      "    <fpage>00</fpage>\n",
      "    <lpage>00</lpage>\n",
      "    <seqno>0</seqno>\n",
      "    <price></price><tocsec>ABC</tocsec>\n",
      "    <arttype type=\"article\"></arttype><doi>00.0000/ABCD.0.0</doi>\n",
      "    <title>ABCDE</title>\n",
      "    <authgrp>\n",
      "    <author><givenname>AB</givenname><middlename>C</middlename><surname>DEF</surname></author>\n",
      "    <aff>ABCDE</aff>\n",
      "    </authgrp>\n",
      "    <!--\n",
      "    optionally the group repeats \n",
      "    <authgrp>\n",
      "    <author anref=\"aA0\"><givenname>AB</givenname><middlename>C</middlename><surname>DEF</surname></author>\n",
      "    <aff>ABCDE</aff>\n",
      "    </author>\n",
      "    </authgrp>\n",
      "    -->\n",
      "    <history>\n",
      "    <received date=\"0000-00-00\"/>\n",
      "    </history>\n",
      "    <cpyrt>\n",
      "    <cpyrtdate date=\"0000\" /><cpyrtholder>ABCD</cpyrtholder>\n",
      "    </cpyrt>\n",
      "    </article>\n",
      "    '''\n",
      "    entries_list = strin.split('</article>')\n",
      "    entries_list = entries_list[:-1] # drop the last entry: it is empty\n",
      "    entry_dict = {'journal':[],'print_date':[],'journ_sec':[],'doi':[],'title':[],\n",
      "                  'authors':[], 'pacs':[], 'publication_year':[]}\n",
      "    dropped_entries = 0\n",
      "    for entry in entries_list:\n",
      "        entry = regularize_entry(entry)\n",
      "        journal, subsplit = get_content_rest(entry, '<journal','/journal>','>[a-zA-Z ]*<')\n",
      "        journal = string.replace(journal,'<','')\n",
      "        journal = string.replace(journal,'>','')\n",
      "        print_date, subsplit = get_content_rest(subsplit, '<issue','/issue>','[0-9]{4,4}-[0-9]{2,2}-[0-9]{2,2}')\n",
      "        try:\n",
      "            journ_sec, subsplit = get_content_rest(subsplit,'<tocsec','/tocsec>','>[a-zA-Z0-9 ,.:\"\\-]*<')\n",
      "        except:\n",
      "            journ_sec = ''\n",
      "        journ_sec = string.replace(journ_sec,'<','')\n",
      "        journ_sec = string.replace(journ_sec,'>','')\n",
      "        doi, subsplit = get_content_rest(subsplit,'doi')\n",
      "        title, subsplit = get_content_rest(subsplit,'title')\n",
      "        authors, subsplit = get_authors(subsplit)\n",
      "        pacs, subsplit = make_pacs_list(subsplit)\n",
      "        copyrtdate = print_date[:4]\n",
      "        if len(copyrtdate)!=4:\n",
      "            print 'Warning: parsed incorrect  date  information for doi:',doi\n",
      "            print 'date:', copyrtdate\n",
      "        entry_dict['journal'].append(journal)\n",
      "        entry_dict['print_date'].append(print_date)\n",
      "        entry_dict['journ_sec'].append(journ_sec)\n",
      "        entry_dict['doi'].append(doi)\n",
      "        entry_dict['title'].append(title)\n",
      "        entry_dict['authors'].append(authors)\n",
      "        entry_dict['pacs'].append(pacs)\n",
      "        entry_dict['publication_year'].append((copyrtdate))\n",
      "    print 'Number of dropped_entries:',dropped_entries\n",
      "    out_df = pd.DataFrame(entry_dict)\n",
      "    return out_df\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    }
   ],
   "metadata": {}
  }
 ]
}