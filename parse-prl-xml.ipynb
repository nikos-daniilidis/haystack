{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Test the xml parser on the Phys Rev Lett xml data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here, I am evaluating the parser of the APS xml files while parsing the Physical Review Letters record. This is a more interesting aand more complex record. It is larger (174 MB) and has quite a few formatting errors in it (incomplete cells etc). So, I've had to make the parser jump thtrough a few hoops to get the data that I could into a dataframe. I did not want to hunt down every single error, so the performance that you see below is the compromise between fidelity and effort that made the most sense to me.\n",
      "\n",
      "It goes without saying that the web.element xml parser (http://www.clips.ua.ac.be/pattern) could not parse the Phys Rev Lett xml. It would eat up my entire RAM and swap file, before crashing my conmputer -all this while trying to creaate an impossible DOM out of a corrupt xml file. \n",
      "\n",
      "In the following, I look at what my parser does and does not do, before  I dive into the business of trying to classify the documents of the Phys Rev Lett archive. The performance  makes me quite happy. It used 250 MB of RAM and was done in 6 seconds to parse the 95000 entries in the xml archive and organize them to a pandas dataframe. The biggest issues with the parser are that it does not properly read the author affiliations for 14000 out of 87000 article entries, and it does not properly read the pacs information for 5000 out of 75000 articles with missing pacs information. I might fix these issues in the future."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import re\n",
      "import string\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import apsparse"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# set custom css formatting for readability of the IPython notebook. See cs109.org\n",
      "from IPython.core.display import HTML\n",
      "styles = open('custom.css', 'r').read()\n",
      "HTML(styles)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<style>\n",
        "    @font-face {\n",
        "        font-family: \"Computer Modern\";\n",
        "        src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');\n",
        "    }\n",
        "    div.cell{\n",
        "        width:800px;\n",
        "        margin-left:16% !important;\n",
        "        margin-right:auto;\n",
        "    }\n",
        "    h1 {\n",
        "        font-family: Helvetica, serif;\n",
        "    }\n",
        "    h4{\n",
        "        margin-top:12px;\n",
        "        margin-bottom: 3px;\n",
        "       }\n",
        "    div.text_cell_render{\n",
        "        font-family: Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
        "        line-height: 145%;\n",
        "        font-size: 130%;\n",
        "        width:800px;\n",
        "        margin-left:auto;\n",
        "        margin-right:auto;\n",
        "    }\n",
        "\n",
        "    div.text_cell_render li {\n",
        "        line-height: 145%;\n",
        "    }\n",
        "\n",
        "    div.text_cell_render code {\n",
        "        color: rgb(40, 114, 43);\n",
        "        font-family: \"Source Code Pro\", source-code-pro,Consolas, monospace;\n",
        "        font-size: 80%;\n",
        "    }\n",
        "\n",
        "    .CodeMirror{\n",
        "            font-family: \"Source Code Pro\", source-code-pro,Consolas, monospace;\n",
        "    }\n",
        "\n",
        "    .text_cell_render h5 {\n",
        "        font-weight: 300;\n",
        "        font-size: 16pt;\n",
        "        color: #4057A1;\n",
        "        font-style: italic;\n",
        "        margin-bottom: .5em;\n",
        "        margin-top: 0.5em;\n",
        "        display: block;\n",
        "    }\n",
        "\n",
        "    .warning{\n",
        "        color: rgb( 240, 20, 20 )\n",
        "        }\n",
        "\n",
        "    strong{\n",
        "        color: rgb(23, 103, 140);\n",
        "\tborder: 1px solid;\n",
        "    }\n",
        "\n",
        "</style>\n",
        "<script>\n",
        "    MathJax.Hub.Config({\n",
        "                        TeX: {\n",
        "                           extensions: [\"AMSmath.js\"]\n",
        "                           },\n",
        "                tex2jax: {\n",
        "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
        "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
        "                },\n",
        "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
        "                \"HTML-CSS\": {\n",
        "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
        "                }\n",
        "        });\n",
        "</script>\n"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "<IPython.core.display.HTML at 0x7fb12fe79590>"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Read an xml formatted file to string"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "datapath = os.path.join('aps-data','aps-dataset-metadata-2010','PRL.xml')\n",
      "f = open(datapath,'r')\n",
      "PRL_file = f.read()\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "entry_df = apsparse.xml_string_to_dataframe(PRL_file)\n",
      "print entry_df.shape\n",
      "entry_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of dropped_entries: 0\n",
        "(95516, 8)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>authors</th>\n",
        "      <th>doi</th>\n",
        "      <th>journ_sec</th>\n",
        "      <th>journal</th>\n",
        "      <th>pacs</th>\n",
        "      <th>print_date</th>\n",
        "      <th>publication_year</th>\n",
        "      <th>title</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> [(Theodore  Bowen, Palmer Physical Laboratory,...</td>\n",
        "      <td> 10.1103/PhysRevLett.1.11</td>\n",
        "      <td> Articles</td>\n",
        "      <td> Physical Review Letters</td>\n",
        "      <td> []</td>\n",
        "      <td> 1958-07-01</td>\n",
        "      <td> 1958</td>\n",
        "      <td> Observation of Unpolarized \u039b's Produced by 1.5...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> [(Jack L Uretsky, Radiation Laboratory, Univer...</td>\n",
        "      <td> 10.1103/PhysRevLett.1.12</td>\n",
        "      <td> Articles</td>\n",
        "      <td> Physical Review Letters</td>\n",
        "      <td> []</td>\n",
        "      <td> 1958-07-01</td>\n",
        "      <td> 1958</td>\n",
        "      <td>    Photoproduction of Positive Pions from Protons</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> [(Glenn M Frye, Los Alamos Scientific Laborato...</td>\n",
        "      <td> 10.1103/PhysRevLett.1.14</td>\n",
        "      <td> Articles</td>\n",
        "      <td> Physical Review Letters</td>\n",
        "      <td> []</td>\n",
        "      <td> 1958-07-01</td>\n",
        "      <td> 1958</td>\n",
        "      <td>        Antiproton Annihilation into Neutral Pions</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> [(H H Woodbury, General Electric Research Labo...</td>\n",
        "      <td> 10.1103/PhysRevLett.1.16</td>\n",
        "      <td> Articles</td>\n",
        "      <td> Physical Review Letters</td>\n",
        "      <td> []</td>\n",
        "      <td> 1958-07-01</td>\n",
        "      <td> 1958</td>\n",
        "      <td>                                   Spin of Ni^{61}</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> [(A  Ghiorso, Radiation Laboratory and Departm...</td>\n",
        "      <td> 10.1103/PhysRevLett.1.17</td>\n",
        "      <td> Articles</td>\n",
        "      <td> Physical Review Letters</td>\n",
        "      <td> []</td>\n",
        "      <td> 1958-07-01</td>\n",
        "      <td> 1958</td>\n",
        "      <td> Attempts to Confirm the Existence of the 10-Mi...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 8 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "                                             authors  \\\n",
        "0  [(Theodore  Bowen, Palmer Physical Laboratory,...   \n",
        "1  [(Jack L Uretsky, Radiation Laboratory, Univer...   \n",
        "2  [(Glenn M Frye, Los Alamos Scientific Laborato...   \n",
        "3  [(H H Woodbury, General Electric Research Labo...   \n",
        "4  [(A  Ghiorso, Radiation Laboratory and Departm...   \n",
        "\n",
        "                        doi journ_sec                  journal pacs  \\\n",
        "0  10.1103/PhysRevLett.1.11  Articles  Physical Review Letters   []   \n",
        "1  10.1103/PhysRevLett.1.12  Articles  Physical Review Letters   []   \n",
        "2  10.1103/PhysRevLett.1.14  Articles  Physical Review Letters   []   \n",
        "3  10.1103/PhysRevLett.1.16  Articles  Physical Review Letters   []   \n",
        "4  10.1103/PhysRevLett.1.17  Articles  Physical Review Letters   []   \n",
        "\n",
        "   print_date publication_year  \\\n",
        "0  1958-07-01             1958   \n",
        "1  1958-07-01             1958   \n",
        "2  1958-07-01             1958   \n",
        "3  1958-07-01             1958   \n",
        "4  1958-07-01             1958   \n",
        "\n",
        "                                               title  \n",
        "0  Observation of Unpolarized \u039b's Produced by 1.5...  \n",
        "1     Photoproduction of Positive Pions from Protons  \n",
        "2         Antiproton Annihilation into Neutral Pions  \n",
        "3                                    Spin of Ni^{61}  \n",
        "4  Attempts to Confirm the Existence of the 10-Mi...  \n",
        "\n",
        "[5 rows x 8 columns]"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Find what kinds of articles are included, and keep only the published articles"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "article_types = entry_df.journ_sec.unique().tolist()\n",
      "print article_types"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['Articles', 'Editorial', 'Errata', 'ANNOUNCEMENT', 'Erratum', 'EDITORIAL', 'ABSTRACTS-An Announcement', 'NOTICE', 'CORRECTION', 'Comments', 'Announcement', 'Addendum', 'Important Announcement', 'ERRATUM', 'REMINDER', 'Fluids, Thermodynamics, and Related Topics', 'Atoms, Molecules, and Related Topics', 'Solids', 'Nuclei', 'Elementary Particles and Fields', 'Atoms, Nuclei, and Particles in Matter', 'Notice', 'Plasmas, Fluids, Thermodynamics, and Related Topics', 'Atoms and Molecules', 'Fluids, Plasmas, and Electric Discharges', 'Condensed Matter: Structure, Etc.', 'Condensed Matter: Electronic Properties, Etc.', 'General Physics', 'Classical Phenomenology and Applications', 'Cross-Disciplinary Physics', 'Geophysics, Astronomy, and Astrophysics', 'Statement of Policy', 'Article', 'Nuclear Physics', 'Atomic, Molecular, and Optical Physics', 'Plasma and Beam Physics', 'Nonlinear Dynamics, Fluid Dynamics, Classical Optics, Etc.', 'Fundamental Phenomenology and Applications', 'Gravitation and Astrophysics', 'Announcements', 'Nonlinear Dynamics: Fluid Dynamics, Classical Optics, Etc.', 'Interdisciplinary Physics: Biological Physics, Quantum Information, Etc.', 'Condensed Matter: Structure, etc.', 'Condensed Matter: Electronic Properties, etc.', 'Interdisciplinary Physics: Biological Physics, Quantum Information, etc.', 'Nonlinear Dynamics, Fluid Dynamics, Classical Optics, etc.', '', 'General Physics: Statistical and Quantum Mechanics, Quantum Information, etc.', 'Soft Matter, Biological, and Interdisciplinary Physics', 'Editorials and Announcements', 'EDITORIALS, ESSAYS, and ANNOUNCEMENTS']\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "article_category = ['Articles','Fluids, Thermodynamics, and Related Topics', 'Atoms, Molecules, and Related Topics', 'Solids', \n",
      "            'Nuclei', 'Elementary Particles and Fields', 'Atoms, Nuclei, and Particles in Matter',\n",
      "            'Plasmas, Fluids, Thermodynamics, and Related Topics', 'Atoms and Molecules', \n",
      "            'Fluids, Plasmas, and Electric Discharges', 'Condensed Matter: Structure, Etc.', \n",
      "            'Condensed Matter: Electronic Properties, Etc.', 'General Physics', \n",
      "            'Classical Phenomenology and Applications', 'Geophysics, Astronomy, and Astrophysics', \n",
      "            'Article', 'Nuclear Physics', 'Atomic, Molecular, and Optical Physics', 'Plasma and Beam Physics', \n",
      "            'Nonlinear Dynamics, Fluid Dynamics, Classical Optics, Etc.', \n",
      "            'Fundamental Phenomenology and Applications', 'Gravitation and Astrophysics', 'Announcements', \n",
      "            'Nonlinear Dynamics: Fluid Dynamics, Classical Optics, Etc.', \n",
      "            'Interdisciplinary Physics: Biological Physics, Quantum Information, Etc.', \n",
      "            'Condensed Matter: Structure, etc.', 'Condensed Matter: Electronic Properties, etc.', \n",
      "            'Interdisciplinary Physics: Biological Physics, Quantum Information, etc.', \n",
      "            'Nonlinear Dynamics, Fluid Dynamics, Classical Optics, etc.', \n",
      "            'General Physics: Statistical and Quantum Mechanics, Quantum Information, etc.', \n",
      "            'Soft Matter, Biological, and Interdisciplinary Physics','Cross-Disciplinary Physics']\n",
      "comment_category = ['Errata','Erratum', 'CORRECTION', 'Comments', 'Addendum', 'ERRATUM']\n",
      "blank_category = ['']\n",
      "editor_category = ['Editorial','ANNOUNCEMENT', 'EDITORIAL', 'NOTICE', 'Announcement', 'Important Announcement', 'REMINDER', \n",
      "                   'ABSTRACTS-An Announcement', 'Notice', 'Statement of Policy', 'Announcements', 'Editorials and Announcements', \n",
      "                   'EDITORIALS, ESSAYS, and ANNOUNCEMENTS']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "articles = entry_df[entry_df.journ_sec.map(lambda x: x in article_category)]\n",
      "comments = entry_df[entry_df.journ_sec.map(lambda x: x in comment_category)]\n",
      "editorials = entry_df[entry_df.journ_sec.map(lambda x: x in editor_category)]\n",
      "uncategorized = entry_df[entry_df.journ_sec.map(lambda x: x in blank_category)]\n",
      "print 'Total entries: %d' % entry_df.shape[0]\n",
      "print 'Article entries: %d' % articles.shape[0]\n",
      "print 'Comment entries: %d' % comments.shape[0]\n",
      "print 'Editorial entries: %d' % editorials.shape[0]\n",
      "print 'Uncategorized entries: %d' % uncategorized.shape[0]\n",
      "uncategorized.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Total entries: 95516\n",
        "Article entries: 87519\n",
        "Comment entries: 7727\n",
        "Editorial entries: 244\n",
        "Uncategorized entries: 27\n"
       ]
      },
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>authors</th>\n",
        "      <th>doi</th>\n",
        "      <th>journ_sec</th>\n",
        "      <th>journal</th>\n",
        "      <th>pacs</th>\n",
        "      <th>print_date</th>\n",
        "      <th>publication_year</th>\n",
        "      <th>title</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>55280</th>\n",
        "      <td> [(M  Borghesi, The Blackett Laboratory Imperia...</td>\n",
        "      <td> 10.1103/PhysRevLett.81.4274</td>\n",
        "      <td> </td>\n",
        "      <td> Physical Review Letters</td>\n",
        "      <td> [52.40.Nk, 07.60.-j, 52.70.Ds, 52.70.Kz]</td>\n",
        "      <td> 1998-11-09</td>\n",
        "      <td> 1998</td>\n",
        "      <td> Comment on \u201cDynamics of Subpicosecond Relativi...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>61805</th>\n",
        "      <td> [(R  Schuch, None), (S  Madzunkov, None), (E  ...</td>\n",
        "      <td> 10.1103/PhysRevLett.85.5559</td>\n",
        "      <td> </td>\n",
        "      <td> Physical Review Letters</td>\n",
        "      <td> [34.70.+e, 31.25.Jf, 52.20.Hv, 78.70.En]</td>\n",
        "      <td> 2000-12-25</td>\n",
        "      <td> 2000</td>\n",
        "      <td> Unexpected X-Ray Emission due to Formation of ...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>62489</th>\n",
        "      <td> [(C  Eltschka, Physik-Department Technische Un...</td>\n",
        "      <td> 10.1103/PhysRevLett.86.2693</td>\n",
        "      <td> </td>\n",
        "      <td> Physical Review Letters</td>\n",
        "      <td>           [03.65.-w, 31.15.Gy, 33.20.Tp]</td>\n",
        "      <td> 2001-03-19</td>\n",
        "      <td> 2001</td>\n",
        "      <td> Comment on \u201cBreakdown of Bohr's Correspondence...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>62490</th>\n",
        "      <td> [(C  Boisseau, None), (E  Audouard, None), (J ...</td>\n",
        "      <td> 10.1103/PhysRevLett.86.2694</td>\n",
        "      <td> </td>\n",
        "      <td> Physical Review Letters</td>\n",
        "      <td>           [03.65.-w, 31.15.Gy, 33.20.Tp]</td>\n",
        "      <td> 2001-03-19</td>\n",
        "      <td> 2001</td>\n",
        "      <td> Comment on \u201cBreakdown of Bohr's Correspondence...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>62888</th>\n",
        "      <td> [(C  Schwob, Laboratoire Kastler Brossel, Ecol...</td>\n",
        "      <td> 10.1103/PhysRevLett.86.4193</td>\n",
        "      <td> </td>\n",
        "      <td> Physical Review Letters</td>\n",
        "      <td> [06.20.Jr, 21.10.Ft, 31.30.Jv, 99.10.+g]</td>\n",
        "      <td> 2001-04-30</td>\n",
        "      <td> 2001</td>\n",
        "      <td> Erratum: Optical Frequency Measurement of the ...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 8 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "                                                 authors  \\\n",
        "55280  [(M  Borghesi, The Blackett Laboratory Imperia...   \n",
        "61805  [(R  Schuch, None), (S  Madzunkov, None), (E  ...   \n",
        "62489  [(C  Eltschka, Physik-Department Technische Un...   \n",
        "62490  [(C  Boisseau, None), (E  Audouard, None), (J ...   \n",
        "62888  [(C  Schwob, Laboratoire Kastler Brossel, Ecol...   \n",
        "\n",
        "                               doi journ_sec                  journal  \\\n",
        "55280  10.1103/PhysRevLett.81.4274            Physical Review Letters   \n",
        "61805  10.1103/PhysRevLett.85.5559            Physical Review Letters   \n",
        "62489  10.1103/PhysRevLett.86.2693            Physical Review Letters   \n",
        "62490  10.1103/PhysRevLett.86.2694            Physical Review Letters   \n",
        "62888  10.1103/PhysRevLett.86.4193            Physical Review Letters   \n",
        "\n",
        "                                           pacs  print_date publication_year  \\\n",
        "55280  [52.40.Nk, 07.60.-j, 52.70.Ds, 52.70.Kz]  1998-11-09             1998   \n",
        "61805  [34.70.+e, 31.25.Jf, 52.20.Hv, 78.70.En]  2000-12-25             2000   \n",
        "62489            [03.65.-w, 31.15.Gy, 33.20.Tp]  2001-03-19             2001   \n",
        "62490            [03.65.-w, 31.15.Gy, 33.20.Tp]  2001-03-19             2001   \n",
        "62888  [06.20.Jr, 21.10.Ft, 31.30.Jv, 99.10.+g]  2001-04-30             2001   \n",
        "\n",
        "                                                   title  \n",
        "55280  Comment on \u201cDynamics of Subpicosecond Relativi...  \n",
        "61805  Unexpected X-Ray Emission due to Formation of ...  \n",
        "62489  Comment on \u201cBreakdown of Bohr's Correspondence...  \n",
        "62490  Comment on \u201cBreakdown of Bohr's Correspondence...  \n",
        "62888  Erratum: Optical Frequency Measurement of the ...  \n",
        "\n",
        "[5 rows x 8 columns]"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Fix uncategorized entries -> done except for 27 comments and articles. I think I can live with that."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Here is an example of aan entry which is not properly parsed. The <tocsec> cell is empty.\n",
      "entries_list = PRL_file.split('</article>')\n",
      "entries_list = entries_list[:-1]\n",
      "print entries_list[55280]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<article doi=\"10.1103/PhysRevLett.81.4274\">\n",
        "<journal jcode=\"PRL\" short=\"Phys. Rev. Lett.\">Physical Review Letters</journal>\n",
        "<volume>81</volume>\n",
        "<issue printdate=\"1998-11-09\">19</issue>\n",
        "<fpage>4274</fpage>\n",
        "<lpage>4274</lpage>\n",
        "<seqno>1</seqno>\n",
        "<price></price><tocsec code=\"K5\"></tocsec>\n",
        "<arttype type=\"comment\"></arttype><doi>10.1103/PhysRevLett.81.4274</doi>\n",
        "<title>Comment on \u201cDynamics of Subpicosecond Relativistic Laser Pulse Self-Channeling in an Underdense Preformed Plasma\u201d</title>\n",
        "<authgrp>\n",
        "<author><givenname>M.</givenname><surname>Borghesi</surname></author>\n",
        "<author><givenname>A.</givenname><middlename>J.</middlename><surname>MacKinnon</surname></author>\n",
        "<author><givenname>R.</givenname><middlename>J.</middlename><surname>Taylor</surname></author>\n",
        "<author><givenname>O.</givenname><surname>Willi</surname></author>\n",
        "<aff>The Blackett Laboratory Imperial College of Science, Technology and Medicine London, United Kingdom</aff>\n",
        "</authgrp>\n",
        "<history>\n",
        "<received date=\"1998-03-18\"/>\n",
        "</history>\n",
        "<pacs>\n",
        "<pacscode>52.40.Nk</pacscode>\n",
        "<pacscode>07.60.-j</pacscode>\n",
        "<pacscode>52.70.Ds</pacscode>\n",
        "<pacscode>52.70.Kz</pacscode>\n",
        "</pacs>\n",
        "<cpyrt>\n",
        "<cpyrtdate date=\"1998\" /><cpyrtholder>The American Physical Society</cpyrtholder>\n",
        "</cpyrt>\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Test for problems in journal, print_date, journ_sec, doi, title, authors, and copyright  identification"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def authors_ok(auth):\n",
      "    try:\n",
      "        ok = len(auth)>0\n",
      "        for a  in auth:\n",
      "            ok = ok and (not a[0] is None)\n",
      "    except:\n",
      "        return False\n",
      "    return ok\n",
      " \n",
      "#x = articles.authors[0]\n",
      "#authors_ok(x)\n",
      "df2 = articles[articles.authors.map(lambda x: authors_ok(x) )]\n",
      "print 'Found %d articles with properly parsed author name information.' % df2.shape[0] # ok\n",
      "#df2.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Found 87517 articles with properly parsed author name information.\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def affiliations_ok(auth):\n",
      "    try:\n",
      "        ok = len(auth)>0\n",
      "        for a  in auth:\n",
      "            ok = ok and (not a[1] is None)\n",
      "    except:\n",
      "        return False\n",
      "    return ok\n",
      " \n",
      "#x = articles.authors[0]\n",
      "#authors_ok(x)\n",
      "df2 = articles[articles.authors.map(lambda x: affiliations_ok(x) )]\n",
      "print 'Found %d articles with propperly parsed author affiliation information' % df2.shape[0] # ok\n",
      "#df2.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Found 63071 articles with propperly parsed author affiliation information\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df2 = articles[articles['pacs'].map(lambda x: len(x)==0)]\n",
      "print 'Found %d articles without pacs number information.' % df2.shape[0]#ok\n",
      "year_list = df2.publication_year.tolist()\n",
      "year_list = [int(x) for x in year_list]\n",
      "print 'Missing pacs are between years %d and %d.' %(min(year_list),max(year_list))\n",
      "all_year_list = articles.publication_year.tolist()\n",
      "all_year_list = [int(x) for x in all_year_list]\n",
      "num_no_pacs = len([x for x in all_year_list if x<1975])\n",
      "print 'Pacs was introduced in 1975. Number of articles before 1975: %d' % num_no_pacs\n",
      "print 'This leaves %d articles published in 1975 and later with improperly parsed pacs information.' % (df2.shape[0]-num_no_pacs)\n",
      "#df2.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Found 17709 articles without pacs number information.\n",
        "Missing pacs are between years 1958 and 1996.\n",
        "Pacs was introduced in 1975. Number of articles before 1975: 12544\n",
        "This leaves 5165 articles published in 1975 and later with improperly parsed pacs information.\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df2 = entry_df[entry_df['print_date'].map(lambda x: len(x)==10)]\n",
      "print '%d out of %d publication dates were correctly parsed.' % (df2.shape[0],entry_df.shape[0])#ok"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "95516 out of 95516 publication dates were correctly parsed.\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df2 = entry_df[entry_df['publication_year'].map(lambda x: 1958<=int(x)<=2009)]\n",
      "print '%d out of %d publication years were correctly parsed.' % (df2.shape[0],entry_df.shape[0])#okdf2.shape # ok"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "95516 out of 95516 publication years were correctly parsed.\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def doi_ok(doi_str,core_str):\n",
      "    '''\n",
      "    check if aa doi string has the expected formatting\n",
      "    '''\n",
      "    p = re.compile(core_str+'.[0-9]{1,3}.[0-9]{1,6}')\n",
      "    # 10.1103/PhysRevLett.85.5559\n",
      "    m = p.search(doi_str)\n",
      "    if m:\n",
      "        return True\n",
      "    else:\n",
      "        return False\n",
      "#print doi_ok('10.1103/PhysRevLett.85.5559','10.1103/PhysRevLett')\n",
      "\n",
      "df2 = entry_df[entry_df['doi'].map(lambda x: doi_ok(x,'10.1103/PhysRevLett'))]\n",
      "print '%d out of %d doi numbers were correctly parsed.' % (df2.shape[0],entry_df.shape[0])#ok"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "95516 out of 95516 doi numbers were correctly parsed.\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Appendix: Test and development using function snippets (can be confusing)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Test parsing of the author group string"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "try:\n",
      "    affiliation = authgrp.split('</aff>')[0].split('<aff>')[1]\n",
      "except:\n",
      "    affiliation = None\n",
      "print affiliation\n",
      "authors = []\n",
      "cnt = 0\n",
      "auth_lst = authgrp.split('<aff>')[0]\n",
      "##\n",
      "author, auth_lst = get_content_rest(auth_lst,'author')\n",
      "first,restname = get_content_rest(author,'givenname')\n",
      "mid, restname = get_content_rest(restname,'middlename')\n",
      "last,restname = get_content_rest(restname,'surname')\n",
      "authors.append((string.join([first,mid,last]).replace('.',''),affiliation))\n",
      "print authors[0]\n",
      "print auth_lst\n",
      "author, auth_lst = get_content_rest(auth_lst,'author')\n",
      "first,restname = get_content_rest(author,'givenname')\n",
      "mid, restname = get_content_rest(restname,'middlename')\n",
      "last,restname = get_content_rest(restname,'surname')\n",
      "authors.append((string.join([first,mid,last]).replace('.',''),affiliation))\n",
      "print authors[1]\n",
      "print len(auth_lst)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Laboratory of Physics, University of Illinois\n",
        "('David W Cornelius', 'Laboratory of Physics, University of Illinois')\n",
        "\n",
        "</author>\n",
        "('  ', 'Laboratory of Physics, University of Illinois')\n",
        "10\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Test parsing of each article string"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "entry = entries_list[0]\n",
      "subsplit = entry.split('</journal>')\n",
      "journal  = subsplit[0]\n",
      "journal = journal[journal.rfind('>')+1:]\n",
      "subsplit = subsplit[1].split('</tocsec>')\n",
      "journ_sec = subsplit[0].split('<tocsec>')[1]\n",
      "subsplit = subsplit[1].split('</doi>')\n",
      "doi = subsplit[0].split('<doi>')[1]\n",
      "subsplit = subsplit[1].split('</title>')\n",
      "title = subsplit[0].split('<title>')[1]\n",
      "subsplit = subsplit[1].split('</authgrp>')\n",
      "# here add the function which returns the list of (author,affiliation) tuples\n",
      "print journal"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Physical Review\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Test parsing of xml content"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "string_in = '<aa>date = \"0000-00-00\" <></aa>\\n<b>B</b>\\n<b>BB</b>\\n<c>C</c>'\n",
      "tag_str = '<b>'\n",
      "tag_str_exception = 'd'\n",
      "start_plus = 0\n",
      "end_minus = 0\n",
      "c,r = get_content_rest(string_in,'<aa>','</aa>','[0-9]{4,4}-[0-9]{2,2}-[0-9]{2,2}')\n",
      "print c,r"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0000-00-00 \n",
        "<b>B</b>\n",
        "<b>BB</b>\n",
        "<c>C</c>\n"
       ]
      }
     ],
     "prompt_number": 189
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Test regular expression matching"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#s = '<author anref=\"n2\"><givenname>W.</givenname><middlename>H.</middlename><surname>Tanttila</surname></author><aff>University of Washington, Seattle, Washington</aff></authgrp>'\n",
      "#print s\n",
      "#p = re.compile(' anref=\"[a-zA-Z0-9]*\"')\n",
      "#m = p.search(s)\n",
      "#print string.replace(s,m.group(),'')\n",
      "s = '<journal jcode=\"PR\" short=\"Phys. Rev.\">Physical Review</journal>'\n",
      "print regularize_entry(s)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<journal>Physical Review</journal>\n"
       ]
      }
     ],
     "prompt_number": 88
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Test author list parsing"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "authgrp_str = string.join(['<authgrp>\\n<author><givenname>F.</givenname><middlename>B.</middlename>',\n",
      "'<surname>Harris</surname></author>\\n<aff>Massachusetts Institute of Technology, Laboratory ',\n",
      "'for Nuclear Science, Cambridge, Massachusetts</aff>\\n</authgrp>\\n',\n",
      "'<authgrp>\\n<author><givenname>I.</givenname><middlename>Escobar</middlename>',\n",
      "'<surname>V.</surname></author>\\n<aff>Universidad Mayor de San Andr\u00e9s, La Paz, Bolivia</aff>',\n",
      "'\\n</authgrp>'])\n",
      "#print authgrp_str\n",
      "al = make_author_list(authgrp_str)\n",
      "print al"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<givenname>F.</givenname><middlename>B.</middlename> <surname>Harris</surname>\n",
        "F.\n",
        "[('F B Harris', 'Massachusetts Institute of Technology, Laboratory  for Nuclear Science, Cambridge, Massachusetts')]\n"
       ]
      }
     ],
     "prompt_number": 129
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Test parsing of PRL "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#entries_list = PRL_file.split('</article>')\n",
      "#PR_file = PRL_file[:1347]\n",
      "#print PR_file\n",
      "#entry  = PR_file\n",
      "entry = entries_list[67000]\n",
      "entry = regularize_entry(entry)\n",
      "print entry\n",
      "journal, subsplit = get_content_rest(entry, 'journal')\n",
      "print journal\n",
      "print_date, subsplit = get_content_rest(subsplit, '<issue','</issue>','[0-9]{4,4}-[0-9]{2,2}-[0-9]{2,2}')\n",
      "print print_date\n",
      "journ_sec, subsplit = get_content_rest(subsplit,'<tocsec','tocsec>','>[a-zA-Z ,.:\"]*<')\n",
      "journ_sec = string.replace(journ_sec,'<','')\n",
      "journ_sec = string.replace(journ_sec,'>','')\n",
      "print journ_sec\n",
      "doi, subsplit = get_content_rest(subsplit,'doi')\n",
      "print doi\n",
      "title, subsplit = get_content_rest(subsplit,'title')\n",
      "print title\n",
      "authors = []\n",
      "while string.find(subsplit,'<authgrp>')>-1:\n",
      "    authgrp, subsplit = get_content_rest(subsplit,'authgrp')\n",
      "    #print subsplit\n",
      "    #resp = raw_input('Continue? (y/n) ')\n",
      "    #cont = resp == 'y'\n",
      "    #print authgrp\n",
      "    al = make_author_list(authgrp)\n",
      "    #print al\n",
      "    authors.extend(al)\n",
      "print authors\n",
      "copyrtdate, subsplit = get_content_rest(subsplit,'<cpyrtdate', '</cpyrtholder>','[0-9]{4,4}')\n",
      "print copyrtdate"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "<article doi=\"10.1103/PhysRevLett.89.018301\">\n",
        "<journal>Physical Review Letters</journal>\n",
        "<volume>89</volume>\n",
        "<issue printdate=\"2002-07-01\">1</issue>\n",
        "<eid>018301</eid>\n",
        "<numpages>4</numpages>\n",
        "<price></price><tocsec code=\"L8-83A\">Interdisciplinary Physics: Biological Physics, Quantum Information, etc.</tocsec>\n",
        "<arttype type=\"article\"></arttype><doi>10.1103/PhysRevLett.89.018301</doi>\n",
        "<title>Quantum-Classical Transition Induced by Electrical Measurement</title>\n",
        "<authgrp>\n",
        "<author><givenname>D.</givenname><surname>Mozyrsky</surname></author>\n",
        "<author><givenname>I.</givenname><surname>Martin</surname></author>\n",
        "<aff>Theoretical Division, Los Alamos National Laboratory, Los Alamos, New Mexico 87545</aff>\n",
        "</authgrp>\n",
        "<history>\n",
        "<received date=\"2002-03-25\"/>\n",
        "<published date=\"2002-06-13\"/>\n",
        "</history>\n",
        "<pacs>\n",
        "<pacscode>85.85.+j</pacscode>\n",
        "<pacscode>05.30.-d</pacscode>\n",
        "<pacscode>05.60.Gg</pacscode>\n",
        "</pacs>\n",
        "<cpyrt>\n",
        "<cpyrtdate date=\"2002\" /><cpyrtholder>The American Physical Society</cpyrtholder>\n",
        "</cpyrt>\n",
        "\n",
        "Physical Review Letters\n",
        "2002-07-01\n",
        "Interdisciplinary Physics: Biological Physics, Quantum Information, etc.\n",
        "10.1103/PhysRevLett.89.018301\n",
        "Quantum-Classical Transition Induced by Electrical Measurement\n",
        "[('D  Mozyrsky', 'Theoretical Division, Los Alamos National Laboratory, Los Alamos, New Mexico 87545'), ('I  Martin', 'Theoretical Division, Los Alamos National Laboratory, Los Alamos, New Mexico 87545')]\n",
        "2002\n"
       ]
      }
     ],
     "prompt_number": 86
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "entries_list = PRL_file.split('</article>')\n",
      "entry = entries_list[83215]\n",
      "#entry = regularize_entry(entry)\n",
      "#print 'entry:',entry\n",
      "#for ch in entry:\n",
      "#    print 'character:',ch\n",
      "journal, subsplit = get_content_rest(entry, '<journal','/journal>','>[a-zA-Z ]*<')\n",
      "#if len(journal)==0:\n",
      "#    print 'entry 1:',entry\n",
      "journal = string.replace(journal,'<','')\n",
      "journal = string.replace(journal,'>','')\n",
      "print journal\n",
      "print_date, subsplit = get_content_rest(subsplit, '<issue','/issue>','[0-9]{4,4}-[0-9]{2,2}-[0-9]{2,2}')\n",
      "try:\n",
      "    journ_sec, subsplit = get_content_rest(subsplit,'<tocsec','/tocsec>','>[a-zA-Z ,.:\"]*<') ## NOT HERE!!!!\n",
      "except:\n",
      "    journ_sec = ''\n",
      "journ_sec = string.replace(journ_sec,'<','')\n",
      "journ_sec = string.replace(journ_sec,'>','')\n",
      "print journ_sec\n",
      "doi, subsplit = get_content_rest(subsplit,'doi')\n",
      "title, subsplit = get_content_rest(subsplit,'title')\n",
      "print doi\n",
      "print title\n",
      "#print subsplit\n",
      "authors = []\n",
      "if terms_matched(subsplit,['authgrp']):\n",
      "    while string.find(subsplit,'<authgrp>')>-1:\n",
      "        authgrp, subsplit = get_content_rest(subsplit,'authgrp')\n",
      "        al = make_author_list(authgrp)\n",
      "        authors.extend(al)\n",
      "        print subsplit\n",
      "else:\n",
      "    count = 0\n",
      "    while string.find(subsplit,'author')>-1:\n",
      "        authgrp, subsplit = get_content_rest(subsplit,'<author','/author>','>[<>./a-zA-Z]*<')\n",
      "        al = make_author_list('<author'+authgrp+'/author>')\n",
      "        authors.extend(al)\n",
      "        count += 1\n",
      "        if count >10:\n",
      "            break      \n",
      "#try:\n",
      "#    copyrtdate, subsplit = get_content_rest(subsplit,'<cpyrtdate', '</cpyrtholder>','[0-9]{4,4}')\n",
      "#except:\n",
      "#    copyrtdate = print_date[:4]\n",
      "print authors\n",
      "print subsplit\n",
      "copyrtdate = print_date[:4]\n",
      "if len(copyrtdate)!=4:\n",
      "    print 'Warning: parsed incorrect  date  information for doi:',doi\n",
      "    print 'date:', copyrtdate"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Physical Review Letters\n",
        "Condensed Matter: Structure, etc.\n",
        "10.1103/PhysRevLett.97.175503\n",
        "Capillary Filling of Anodized Alumina Nanopore Arrays\n",
        "[('Kyle J Alvine', None), ('Oleg G Shpyrko', None), ('Peter S Pershan', None), ('Kyusoon  Shin', None), ('Thomas P Russell', None)]\n",
        "<aff affid=\"a1\">Division of Engineering and Applied Sciences, <institution>Harvard University</institution>, Cambridge, Massachusetts 02138, USA<published date=\"2006-10-27\"/></history><pacs pacsyr=\"2006\"><pacscode>61.10.Eq</pacscode><pacscode>05.70.\u2212a</pacscode><pacscode>68.08.Bc</pacscode></pacs><cpyrt><cpyrtdate date=\"2006\"/><cpyrtholder>The American Physical Society</cpyrtholder></cpyrt> \n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "These are examples of the functions used for parsing. Get the latest ones from apsparse.py"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def terms_matched(entry, terms_list_twice=[], terms_list_thrice = []):\n",
      "    '''\n",
      "    check that all strings in the list terms_list_twice appear in the string 'entry' exactly twice\n",
      "    and all strings in the list terms_list_thrice appear in the string 'entry' exactly three times\n",
      "    returns a boolean\n",
      "    '''\n",
      "    for term in terms_list_twice:\n",
      "        if string.count(entry,term) <> 2:\n",
      "            return False\n",
      "    for term in terms_list_thrice:\n",
      "        if string.count(entry,term) <> 3:\n",
      "            return False\n",
      "    return True\n",
      "\n",
      "def get_content_rest(string_in, tag_str, tag_str_exception = '', reg_expr = ''):\n",
      "    '''\n",
      "    Split an xml formatted string. Return a tuple of two strings, content and rest.\n",
      "    The asssumed format of string_in is:\n",
      "    <tag_str>content</tag_str>rest\n",
      "    except if non-empty tag_str_exception is provided, when I assume the format:\n",
      "    <tag_str>'ignored'reg_expr'ignored'<tag_str_excpetion>rest\n",
      "    In the latter case, a regular expression string describes the format of the content \n",
      "    which gets returned. In both cases, rest is the part of string_in after the end of \n",
      "    the </tag_str> or <tag_sre_exception> substring\n",
      "    '''\n",
      "    if len(tag_str_exception)==0:\n",
      "        l = '<'+tag_str+'>'\n",
      "        h = '</'+tag_str+'>'\n",
      "    else:\n",
      "        l = tag_str\n",
      "        h = tag_str_exception\n",
      "    if string.find(string_in,l)>-1:\n",
      "        Ilow =  string.find(string_in,l)+len(l)\n",
      "    else:\n",
      "        Ilow = 0\n",
      "    if string.find(string_in,h)>-1:\n",
      "        Ihigh = string.find(string_in,h)\n",
      "    else:\n",
      "        Ihigh, end_minus = 0,0\n",
      "        h = ''\n",
      "    if len(reg_expr) == 0:\n",
      "        content = string_in[Ilow:Ihigh]\n",
      "    else:\n",
      "        p = re.compile(reg_expr)\n",
      "        m = p.search(string_in[Ilow:Ihigh])\n",
      "        if m:\n",
      "            content = m.group()\n",
      "        else:\n",
      "            content = ''\n",
      "    rest = string_in[Ihigh+len(h):]\n",
      "    return content,rest\n",
      "\n",
      "def make_author_list(authgrp_str):\n",
      "    '''\n",
      "    Make a list of (author, affiliation) tuples for the author group in authgrp_str\n",
      "    If there is no affiliation in the group, affiliation is set to ''\n",
      "    Returns: authors, a list of (author,affiliation)\n",
      "    '''\n",
      "    try:\n",
      "        affiliation = authgrp_str.split('</aff>')[0].split('<aff>')[1]\n",
      "    except:\n",
      "        affiliation = None\n",
      "    cnt = 0\n",
      "    authors = []\n",
      "    auth_lst = authgrp_str.split('<aff>')[0]\n",
      "    while 1:\n",
      "        author, auth_lst = get_content_rest(auth_lst,'author')\n",
      "        first,restname = get_content_rest(author,'givenname')\n",
      "        mid, restname = get_content_rest(restname,'middlename')\n",
      "        last,restname = get_content_rest(restname,'surname')\n",
      "        authors.append((string.join([first,mid,last]).replace('.',''),affiliation))\n",
      "        if len(auth_lst)<11:\n",
      "            break\n",
      "        cnt += 1\n",
      "        if cnt>10:\n",
      "            break\n",
      "    return authors\n",
      "\n",
      "def make_pacs_list(string_in):\n",
      "    '''\n",
      "    Get the list of pacs numbers.\n",
      "    '''\n",
      "    pacs = []\n",
      "    sub = string_in\n",
      "    if string.find(sub,'<pacs')>-1 and string.find(sub,'</pacs')>-1:\n",
      "        count = 0\n",
      "        while string.find(sub,'<pacscode>')>-1:\n",
      "            newpacs, sub = get_content_rest(sub,'pacscode')\n",
      "            pacs.extend([newpacs])\n",
      "            count += 1\n",
      "            if count > 10:\n",
      "                break\n",
      "    else:\n",
      "        pacs = []\n",
      "    return pacs,sub\n",
      "\n",
      "def regularize_entry(strng):\n",
      "    '''\n",
      "    Fix known html formatting issues in the article entry xml strings\n",
      "    '''\n",
      "    strout = string.replace(strng,'\\n',' ')\n",
      "    strout = string.replace(strout,'aff >','aff>')\n",
      "    p = re.compile(' anref=\"[a-zA-Z0-9]*\"')\n",
      "    m = p.search(strout)\n",
      "    if m:\n",
      "        strout = string.replace(strout,m.group(),'')\n",
      "    p = re.compile(' jcode=\"[a-zA-Z.= \"]*\"')\n",
      "    m = p.search(strout)\n",
      "    if m:\n",
      "        strout = string.replace(strout,m.group(),'')\n",
      "    return strout\n",
      "\n",
      "def get_authors(string_in):\n",
      "    '''\n",
      "    get the list of authors and affiliations. handles the bad xml formatting cases\n",
      "    '''\n",
      "    authors = []\n",
      "    sub = string_in\n",
      "    if string.find(sub,'</authgrp')>-1:\n",
      "        count = 0\n",
      "        while string.find(sub,'<authgrp>')>-1:\n",
      "            authgrp, sub = get_content_rest(sub,'authgrp')\n",
      "            al = make_author_list(authgrp)\n",
      "            authors.extend(al)\n",
      "            count += 1\n",
      "            if count > 100:\n",
      "                break\n",
      "    else:\n",
      "        count = 0\n",
      "        while string.find(sub,'author')>-1:\n",
      "            authgrp, sub = get_content_rest(sub,'<author','/author>','>[<>./a-zA-Z]*<')\n",
      "            al = make_author_list('<author'+authgrp+'/author>')\n",
      "            authors.extend(al)\n",
      "            count += 1\n",
      "            if count > 101:\n",
      "                break\n",
      "    return authors,sub\n",
      "\n",
      "def xml_string_to_dataframe(strin):\n",
      "    '''\n",
      "    Parse an xml string and put the information in a pandas DataFrame. \n",
      "    The xml string consists of repeated blocks of the following form:\n",
      "    <article doi=\"00.0000/ABCD.0.0\">\n",
      "    <journal jcode=\"AB\" short=\"ABCDEF\">ABCDEFGH</journal>\n",
      "    <volume>0</volume>\n",
      "    <issue printdate=\"0000-00-00\">0</issue>\n",
      "    <fpage>00</fpage>\n",
      "    <lpage>00</lpage>\n",
      "    <seqno>0</seqno>\n",
      "    <price></price><tocsec>ABC</tocsec>\n",
      "    <arttype type=\"article\"></arttype><doi>00.0000/ABCD.0.0</doi>\n",
      "    <title>ABCDE</title>\n",
      "    <authgrp>\n",
      "    <author><givenname>AB</givenname><middlename>C</middlename><surname>DEF</surname></author>\n",
      "    <aff>ABCDE</aff>\n",
      "    </authgrp>\n",
      "    <!--\n",
      "    optionally the group repeats \n",
      "    <authgrp>\n",
      "    <author anref=\"aA0\"><givenname>AB</givenname><middlename>C</middlename><surname>DEF</surname></author>\n",
      "    <aff>ABCDE</aff>\n",
      "    </author>\n",
      "    </authgrp>\n",
      "    -->\n",
      "    <history>\n",
      "    <received date=\"0000-00-00\"/>\n",
      "    </history>\n",
      "    <cpyrt>\n",
      "    <cpyrtdate date=\"0000\" /><cpyrtholder>ABCD</cpyrtholder>\n",
      "    </cpyrt>\n",
      "    </article>\n",
      "    '''\n",
      "    entries_list = strin.split('</article>')\n",
      "    entries_list = entries_list[:-1] # drop the last entry: it is empty\n",
      "    entry_dict = {'journal':[],'print_date':[],'journ_sec':[],'doi':[],'title':[],\n",
      "                  'authors':[], 'pacs':[], 'publication_year':[]}\n",
      "    dropped_entries = 0\n",
      "    for entry in entries_list:\n",
      "        entry = regularize_entry(entry)\n",
      "        journal, subsplit = get_content_rest(entry, '<journal','/journal>','>[a-zA-Z ]*<')\n",
      "        journal = string.replace(journal,'<','')\n",
      "        journal = string.replace(journal,'>','')\n",
      "        print_date, subsplit = get_content_rest(subsplit, '<issue','/issue>','[0-9]{4,4}-[0-9]{2,2}-[0-9]{2,2}')\n",
      "        try:\n",
      "            journ_sec, subsplit = get_content_rest(subsplit,'<tocsec','/tocsec>','>[a-zA-Z ,.:\"\\-]*<')\n",
      "        except:\n",
      "            journ_sec = ''\n",
      "        journ_sec = string.replace(journ_sec,'<','')\n",
      "        journ_sec = string.replace(journ_sec,'>','')\n",
      "        doi, subsplit = get_content_rest(subsplit,'doi')\n",
      "        title, subsplit = get_content_rest(subsplit,'title')\n",
      "        authors, subsplit = get_authors(subsplit)\n",
      "        pacs, subsplit = make_pacs_list(subsplit)\n",
      "        copyrtdate = print_date[:4]\n",
      "        if len(copyrtdate)!=4:\n",
      "            print 'Warning: parsed incorrect  date  information for doi:',doi\n",
      "            print 'date:', copyrtdate\n",
      "        entry_dict['journal'].append(journal)\n",
      "        entry_dict['print_date'].append(print_date)\n",
      "        entry_dict['journ_sec'].append(journ_sec)\n",
      "        entry_dict['doi'].append(doi)\n",
      "        entry_dict['title'].append(title)\n",
      "        entry_dict['authors'].append(authors)\n",
      "        entry_dict['pacs'].append(pacs)\n",
      "        entry_dict['publication_year'].append((copyrtdate))\n",
      "    print 'Number of dropped_entries:',dropped_entries\n",
      "    out_df = pd.DataFrame(entry_dict)\n",
      "    return out_df\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    }
   ],
   "metadata": {}
  }
 ]
}